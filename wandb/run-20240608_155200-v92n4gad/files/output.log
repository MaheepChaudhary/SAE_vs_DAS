
passed dict emned path ./dictionary_learning/dictionaries/pythia-70m-deduped/embed
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
  0%|                                          | 0/282 [00:00<?, ?it/s]You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.






















100%|████████████████████████████████| 282/282 [00:46<00:00,  6.07it/s]
















100%|████████████████████████████████| 282/282 [00:33<00:00,  8.35it/s]















100%|████████████████████████████████| 282/282 [00:32<00:00,  8.80it/s]






















100%|████████████████████████████████| 282/282 [00:43<00:00,  6.49it/s]
















100%|████████████████████████████████| 282/282 [00:32<00:00,  8.66it/s]















100%|████████████████████████████████| 282/282 [00:32<00:00,  8.72it/s]






















100%|████████████████████████████████| 282/282 [00:43<00:00,  6.42it/s]
















100%|████████████████████████████████| 282/282 [00:32<00:00,  8.70it/s]















100%|████████████████████████████████| 282/282 [00:33<00:00,  8.43it/s]

























100%|████████████████████████████████| 282/282 [00:49<00:00,  5.70it/s]


























100%|████████████████████████████████| 282/282 [00:54<00:00,  5.13it/s]




































100%|████████████████████████████████| 282/282 [01:13<00:00,  3.82it/s]











































100%|████████████████████████████████| 282/282 [01:28<00:00,  3.20it/s]






















100%|████████████████████████████████| 282/282 [00:46<00:00,  6.13it/s]


















100%|████████████████████████████████| 282/282 [00:37<00:00,  7.45it/s]































100%|████████████████████████████████| 282/282 [01:00<00:00,  4.65it/s]



















100%|████████████████████████████████| 282/282 [00:38<00:00,  7.24it/s]


















100%|████████████████████████████████| 282/282 [00:38<00:00,  7.40it/s]





























100%|████████████████████████████████| 282/282 [00:59<00:00,  4.70it/s]

















100%|████████████████████████████████| 282/282 [00:37<00:00,  7.51it/s]


















100%|████████████████████████████████| 282/282 [00:37<00:00,  7.60it/s]


































100%|████████████████████████████████| 282/282 [01:09<00:00,  4.07it/s]


















100%|████████████████████████████████| 282/282 [00:36<00:00,  7.63it/s]


















100%|████████████████████████████████| 282/282 [00:37<00:00,  7.44it/s]




























100%|████████████████████████████████| 282/282 [00:56<00:00,  4.95it/s]



















100%|████████████████████████████████| 282/282 [00:41<00:00,  6.80it/s]

















100%|████████████████████████████████| 282/282 [00:37<00:00,  7.53it/s]




























100%|████████████████████████████████| 282/282 [00:55<00:00,  5.08it/s]

















100%|████████████████████████████████| 282/282 [00:37<00:00,  7.60it/s]


















100%|████████████████████████████████| 282/282 [00:37<00:00,  7.47it/s]































100%|████████████████████████████████| 282/282 [01:06<00:00,  4.27it/s]


















100%|████████████████████████████████| 282/282 [00:37<00:00,  7.53it/s]



















100%|████████████████████████████████| 282/282 [00:39<00:00,  7.13it/s]


























100%|████████████████████████████████| 282/282 [00:53<00:00,  5.27it/s]



















100%|████████████████████████████████| 282/282 [00:39<00:00,  7.16it/s]



















100%|████████████████████████████████| 282/282 [00:44<00:00,  6.29it/s]


























100%|████████████████████████████████| 282/282 [00:52<00:00,  5.33it/s]



















100%|████████████████████████████████| 282/282 [00:39<00:00,  7.14it/s]

















100%|████████████████████████████████| 282/282 [00:37<00:00,  7.59it/s]

  6%|█▊                               | 16/282 [00:03<00:55,  4.75it/s]
Traceback (most recent call last):
  File "/home/atticus/maheep/SAE_vs_DAS/main.py", line 340, in <module>
    train(DEVICE=args.device,
  File "/home/atticus/maheep/SAE_vs_DAS/main.py", line 82, in train
    logits, l4_mask_sigmoid = new_model(text, temperature=temprature)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/atticus/maheep/SAE_vs_DAS/model.py", line 136, in forward
    with self.model.trace(text) as tracer:
  File "/home/atticus/.local/lib/python3.10/site-packages/nnsight/models/NNsightModel.py", line 196, in trace
    runner.invoke(*inputs, **invoker_args).__enter__()
  File "/home/atticus/.local/lib/python3.10/site-packages/nnsight/contexts/Invoker.py", line 69, in __enter__
    self.tracer._model._execute(
  File "/home/atticus/.local/lib/python3.10/site-packages/nnsight/models/mixins/Generation.py", line 21, in _execute
    return self._execute_forward(prepared_inputs, *args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/nnsight/models/LanguageModel.py", line 281, in _execute_forward
    return self._model(
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 1034, in forward
    outputs = self.gpt_neox(
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 925, in forward
    outputs = layer(
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 690, in forward
    attention_layer_outputs = self.attention(
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 177, in forward
    qkv = self.query_key_value(hidden_states)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1780, in __torch_function__
    return func(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/utils/_stats.py", line 15, in wrapper
    @functools.wraps(fn)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/atticus/maheep/SAE_vs_DAS/main.py", line 340, in <module>
    train(DEVICE=args.device,
  File "/home/atticus/maheep/SAE_vs_DAS/main.py", line 82, in train
    logits, l4_mask_sigmoid = new_model(text, temperature=temprature)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/atticus/maheep/SAE_vs_DAS/model.py", line 136, in forward
    with self.model.trace(text) as tracer:
  File "/home/atticus/.local/lib/python3.10/site-packages/nnsight/models/NNsightModel.py", line 196, in trace
    runner.invoke(*inputs, **invoker_args).__enter__()
  File "/home/atticus/.local/lib/python3.10/site-packages/nnsight/contexts/Invoker.py", line 69, in __enter__
    self.tracer._model._execute(
  File "/home/atticus/.local/lib/python3.10/site-packages/nnsight/models/mixins/Generation.py", line 21, in _execute
    return self._execute_forward(prepared_inputs, *args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/nnsight/models/LanguageModel.py", line 281, in _execute_forward
    return self._model(
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 1034, in forward
    outputs = self.gpt_neox(
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 925, in forward
    outputs = layer(
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 690, in forward
    attention_layer_outputs = self.attention(
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 177, in forward
    qkv = self.query_key_value(hidden_states)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1780, in __torch_function__
    return func(*args, **kwargs)
  File "/home/atticus/.local/lib/python3.10/site-packages/torch/utils/_stats.py", line 15, in wrapper
    @functools.wraps(fn)
KeyboardInterrupt